{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to IoETPlanet","text":"<ul> <li>Raspberry Pi</li> <li>Installing Docker Engine 19.03 on Raspberry Pi 3 in 2 Minutes</li> <li>Docker Workshop on Raspberry Pi - UPES</li> <li>Unboxing 3.5\u201d Touch Screen RPi LCD for Raspberry Pi 3 in 2 Minutes</li> <li>How to run NodeJS Application on Raspberry Pi</li> <li>Top 5 Cool Projects around Docker, Raspberry Pi &amp; Blinkt! ~ Monitoring Docker Swarm using LEDs \u2013 Part I</li> <li>Running Multi-Node K3s Cluster running on Raspberry Pi using Datadog</li> <li>How I built ARM based Docker Images for Raspberry Pi using buildx CLI Plugin on Docker Desktop?</li> <li>Meet K3s \u2013 A Lightweight Kubernetes Distribution for Raspberry Pi Cluster</li> <li>Turn Your Raspberry Pi into Low-cost CCTV Surveillance Camera(with Night Vision) in 5 Minutes using Docker</li> <li>Building a minimalistic LinuxKit OS on Raspberry Pi 3 using Moby</li> <li>Test-Drive Docker 1.12 on first 64-bit ARM OpenSUSE running on Raspberry Pi 3</li> <li>Assessing the current state of Docker Engine &amp; Tools on Raspberry Pi</li> <li>Running Prometheus Docker container for monitoring Microservices on Raspberry Pi</li> <li>Turn Your Raspberry Pi into Out-of-band Monitoring Device using Docker</li> <li>Building the first CentOS 7.2 ARM docker image on Raspberry Pi 3</li> <li>Docker 1.12.1 on Raspberry Pi 3 in 5 minutes</li> <li> <p>The Rise of Pico: At the Grace Hopper Celebration India</p> </li> <li> <p>NVIDIA Jetson Nano</p> </li> <li>Object Detection with Yolo Made Simple using Docker on NVIDIA Jetson Nano</li> <li>Multi Node k3s Cluster on NVIDIA Jetsin Nano in 5 Minutes</li> <li>Running Minecraft inside Docker Container</li> <li>How to run Docker Compose on Jetson Nano</li> <li>Pico goes Cloudless: Running RTMP &amp; Nginx for Video Streaming using Docker on Jetson Nano locally</li> <li>Redis running inside Docker container on NVIDIA Jetson Nano</li> <li> <p>How to enable RDP on Jetson Nano</p> </li> <li> <p>NVIDIA Jetson AGX Xavier</p> <ul> <li>Getting Started</li> <li>Identifying the Jetson Board</li> <li>Running Docker on Xavier</li> <li>Running JTOP on Xavier</li> <li>Running DeepStreaming on Xavier</li> </ul> </li> <li> <p>Pine64</p> <ul> <li>An Overview of $200 Pinebook Pro ARM Laptop </li> <li>A First look at Docker on Pinebook Pro</li> <li>Docker Compose on Pinebook Pro Laptop</li> <li>Installing K3s on Manjaro</li> <li>Running Portainer on Pine64</li> </ul> </li> </ul>"},{"location":"nvidia/docker-on-jetson-nano/","title":"Getting Started with Docker on  NVIDIA Jetson Nano","text":""},{"location":"nvidia/docker-on-jetson-nano/#verifying-if-it-is-shipped-with-docker-binaries","title":"Verifying if it is shipped with Docker Binaries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker version\n[sudo] password for ajeetraina: \nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:       \n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#checking-docker-runtime","title":"Checking Docker runtime","text":"<p>Starting with JetPack 4.2, NVIDIA has introduced a container runtime with Docker integration. This custom runtime enables Docker containers to access the underlying GPUs available in the Jetson family.</p> <pre><code>pico@pico1:/tmp/docker-build$ sudo nvidia-docker version\nNVIDIA Docker: 2.0.3\nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#installing-docker-compose-on-nvidia-jetson-nano","title":"Installing Docker Compose on NVIDIA Jetson Nano","text":"<p>Jetson Nano doesnt come with Docker Compose installed by default. You will need to install it first:</p> <pre><code>export DOCKER_COMPOSE_VERSION=1.27.4\nsudo apt-get install libhdf5-dev\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose==\"${DOCKER_COMPOSE_VERSION}\"\napt install python3\napt install python3-pip\npip install docker-compose\n</code></pre> <pre><code>docker-compose version\ndocker-compose version 1.26.2, build unknown\ndocker-py version: 4.3.1\nCPython version: 3.6.9\nOpenSSL version: OpenSSL 1.1.1  11 Sep 2018\n</code></pre> <p>Next, add default runtime for NVIDIA:</p> <p>Edit /etc/docker/daemon.json</p> <pre><code>{\n    \"runtimes\": {\n        \"nvidia\": {\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        }\n    },\n\n    \"default-runtime\": \"nvidia\",\n    \"node-generic-resources\": [ \"NVIDIA-GPU=0\" ]\n}\n\n</code></pre> <p>Restart the Docker Daemon</p> <pre><code>systemctl restart docker\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#identify-the-jetson-board","title":"Identify the Jetson board","text":"<pre><code>pico@pico1:~$ git clone https://github.com/jetsonhacks/jetsonUtilities\nCloning into 'jetsonUtilities'...\nremote: Enumerating objects: 123, done.\nremote: Counting objects: 100% (39/39), done.\nremote: Compressing objects: 100% (30/30), done.\nremote: Total 123 (delta 15), reused 23 (delta 8), pack-reused 84\nReceiving objects: 100% (123/123), 32.87 KiB | 5.48 MiB/s, done.\nResolving deltas: 100% (49/49), done.\npico@pico1:~$ cd jetson\n-bash: cd: jetson: No such file or directory\npico@pico1:~$ cd jetsonUtilities/\n</code></pre> <pre><code>pico@pico1:~/jetsonUtilities$ ls\nLICENSE  README.md  jetsonInfo.py  scripts\n\npico@pico1:~/jetsonUtilities$ python3 jetsonInfo.py \nNVIDIA Jetson Nano (Developer Kit Version)\n L4T 32.4.4 [ JetPack 4.4.1 ]\n   Ubuntu 18.04.5 LTS\n   Kernel Version: 4.9.140-tegra\n CUDA 10.2.89\n   CUDA Architecture: 5.3\n OpenCV version: 4.1.1\n   OpenCV Cuda: NO\n CUDNN: 8.0.0.180\n TensorRT: 7.1.3.0\n Vision Works: 1.6.0.501\n VPI: 4.4.1-b50\n Vulcan: 1.2.70\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#install-the-latest-version-of-cuda","title":"Install the latest version of CUDA","text":"<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/sbsa/cuda-ubuntu1804.pin\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo dpkg -i cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-3-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#verify-docker-runtime","title":"Verify Docker runtime","text":"<pre><code>docker info | grep runtime\n Runtimes: nvidia runc io.containerd.runc.v2 io.containerd.runtime.v1.linux\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#testing-gpu-support","title":"Testing GPU Support","text":"<p>We\u2019ll use the deviceQuery NVIDIA test application (included in L4T) to check that we can access the GPU in the cluster. First, we\u2019ll create a Docker image with the appropriate software, run it directly as Docker, then run it using containerd ctr and finally on the Kubernetes cluster itself.</p>"},{"location":"nvidia/docker-on-jetson-nano/#running-devicequery-on-docker-with-gpu-support","title":"Running deviceQuery on Docker with GPU support","text":""},{"location":"nvidia/docker-on-jetson-nano/#create-a-directory","title":"Create a directory","text":"<pre><code>mkdir test\ncd test\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#copy-the-sample-files","title":"Copy the sample files","text":"<p>Copy the demos where deviceQuery is located to the working directory where the Docker image will be created:</p> <pre><code>cp -R /usr/local/cuda/samples .\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#create-a-dockerfile","title":"Create a Dockerfile","text":"<pre><code>FROM nvcr.io/nvidia/l4t-base:r32.5.0\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends make g++\nCOPY ./samples /tmp/samples\nWORKDIR /tmp/samples/1_Utilities/deviceQuery\nRUN make clean &amp;&amp; make\nCMD [\"./deviceQuery\"]\n</code></pre> <pre><code>sudo docker build -t ajeetraina/jetson_devicequery . -f Dockerfile\n</code></pre> <pre><code>pico@pico2:~/test$ sudo docker run --rm --runtime nvidia ajeetraina/jetson_devicequery:latest\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre> <p>Test 2: Running deviceQuery on containerd with GPU support</p> <p>Since K3s uses containerd as its runtime by default, we will use the ctr command line to test and deploy the deviceQuery image we pushed on containerd with this script:</p> <pre><code>#!/bin/bash\nIMAGE=ajeetraina/jetson_devicequery:latest\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml\nctr i pull docker.io/${IMAGE}\nctr run --rm --gpus 0 --tty docker.io/${IMAGE} deviceQuery\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#execute-the-script","title":"Execute the script","text":"<pre><code>sudo sh usectr.sh\n</code></pre> <pre><code>sudo sh usectr.sh \ndocker.io/ajeetraina/jetson_devicequery:latest:                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550: done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:4438ebff930fb27930d802553e13457783ca8a597e917c030aea07f8ff6645c0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b1cdeb9e69c95684d703cf96688ed2b333a235d5b33f0843663ff15f62576bd4:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:bf60857fb4964a3e3ce57a900bbe47cd1683587d6c89ecbce4af63f98df600aa:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0aac5305d11a81f47ed76d9663a8d80d2963b61c643acfce0515f0be56f5e301:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:37987db6d6570035e25e713f41e665a6d471d25056bb56b4310ed1cb1d79a100:   done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f0f57d03cad8f8d69b1addf90907b031ccb253b5a9fc5a11db83c51aa311cbfb:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:08c23323368d4fde5347276d543c500e1ff9b712024ca3f85172018e9440d8b0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:04da93b342eb651d6b94c74a934a3290697573a907fa0a06067b538095601745:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f84ceb6e8887e9b3b454813459ee97c2b9730869dbd37d4cca4051958b7a5a36:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:93752947af53e2a3225e145b359b956df36e20521b5dde0fe6d3fb92fd2a9538:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b235194751dee33624fc154603f7e25ecdfbb02538fb7d55fa796df9afa95fee:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:905b1329c1d473c79650e33b882d980b3522fb72e58ecd3456c4fb3c4039fe92:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:8931d5ba88b488c949f77f990e8f9198b153ceb71afd0369eac9c39beb38f2d6:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cfb2938be99fb944fe31165bdf44532a5536865ce53b12eb7758d1e2a51ad33e:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:606a67bb8db9a1111022bdc6406442e11c1a66653136c5c777114bf67b61038a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:2f37138d1c8ac71d9314a0f8996ba69579bbc6ee6a57440557bc7eef486ed292:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9ce7ce1da17c2b8149573d1d73132f61a73083f0cd498eeb7a0da404fd77db14:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a36863a728ec9221c83c745f40511946dfd63beca0f10c9afcc774ef7a98e420:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:86dd6e5994e2c15f2783d8d543327479ccee7f3b20023dd962fdb9a211071e16:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f5299db1221c515de91f59d84b79f2f839f9c94a5d0cc7fad04134e23ec9b88a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:15a5811e1a7bf377cbac066b04e0b36b4c1a41ca63eb3c67c17b734577f6beea:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cb893097de39451407d7167b312ec56eaea80baa041877af8239dbe833fa044b:    done           |++++++++++++++++++++++++++++++++++++++| \nelapsed: 81.4s                                                                    total:  305.5  (3.8 MiB/s)                                       \nunpacking linux/arm64/v8 sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550...\n\ndone\n\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n\n\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#test-3-running-devicequery-on-the-k3s-cluster","title":"Test 3: Running deviceQuery on the K3s cluster","text":"<pre><code>pico@pico2:~/test$ cat pod_deviceQuery.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$\n</code></pre> <pre><code>sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery.yaml\npod/devicequery created\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Pending\nIP:           \nIPs:          &lt;none&gt;\nContainers:\n  nvidia:\n    Container ID:  \n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      \n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       ContainerCreating\n    Ready:          False\n    Restart Count:  0\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  78s   default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal  Pulling    77s   kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\npico@pico2:~/test$\n</code></pre> <pre><code>cat pod_deviceQuery_jetson4.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  nodeName: pico4\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$ \n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Running\nIP:           10.42.1.3\nIPs:\n  IP:  10.42.1.3\nContainers:\n  nvidia:\n    Container ID:  containerd://fd502d6bfa55e2f80b2d50bc262e6d6543fd8d09e9708bb78ecec0b2e09621c3\n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      docker.io/ajeetraina/jetson_devicequery@sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550\n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    1\n      Started:      Sun, 13 Jun 2021 09:21:50 -0700\n      Finished:     Sun, 13 Jun 2021 09:21:50 -0700\n    Ready:          False\n    Restart Count:  5\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                    From               Message\n  ----     ------     ----                   ----               -------\n  Normal   Scheduled  7m51s                  default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal   Pulled     5m45s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 2m5.699757621s\n  Normal   Pulled     5m43s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.000839703s\n  Normal   Pulled     5m29s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 967.072951ms\n  Normal   Pulled     4m59s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.025604394s\n  Normal   Created    4m59s (x4 over 5m45s)  kubelet            Created container nvidia\n  Normal   Started    4m59s (x4 over 5m45s)  kubelet            Started container nvidia\n  Warning  BackOff    4m20s (x8 over 5m42s)  kubelet            Back-off restarting failed container\n  Normal   Pulling    2m47s (x6 over 7m51s)  kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery_jetson4.yaml\npod/devicequery configured\n</code></pre>"},{"location":"nvidia/getting-started/","title":"Getting Started with NVIDIA Jetson Nano","text":""},{"location":"nvidia/getting-started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Intent</li> <li>Hardware</li> <li>Software</li> <li>Preparing Your Jetson Nano</li> <li>Flashing SD card image</li> <li>Vefifying Docker Binaries</li> </ol>"},{"location":"nvidia/getting-started/#intent","title":"Intent","text":"<p>Everything and anything you want to know about NVIDIA Jetson Nano, Docker &amp; K3s support</p>"},{"location":"nvidia/getting-started/#hardware","title":"Hardware","text":"<ul> <li>Jetson Nano</li> <li>A Camera Module</li> <li>A 5V 4Ampere Charger</li> <li>64GB SD card</li> </ul>"},{"location":"nvidia/getting-started/#software","title":"Software","text":"<ul> <li>Jetson SD card image from https://developer.nvidia.com/embedded/downloads</li> <li>Etcher software installed on your system</li> </ul>"},{"location":"nvidia/getting-started/#preparing-your-jetson-nano","title":"Preparing Your Jetson Nano","text":""},{"location":"nvidia/getting-started/#1-preparing-your-raspberry-pi-flashing-jetson-sd-card-image","title":"1. Preparing Your Raspberry Pi Flashing Jetson SD Card Image","text":"<ul> <li>Unzip the SD card image</li> <li>Insert SD card into your system. </li> <li>Bring up Etcher tool and select the target SD card to which you want to flash the image.</li> </ul> <pre><code>sudo lshw -C system\npico2                       \n    description: Computer\n    product: NVIDIA Jetson Nano Developer Kit\n    serial: 1422919082257\n    width: 64 bits\n    capabilities: smp cp15_barrier setend swp\n</code></pre>"},{"location":"nvidia/getting-started/#cuda-compiler-and-libraries","title":"CUDA Compiler and Libraries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~/meetup$ nvcc --version\n-bash: nvcc: command not found\najeetraina@ajeetraina-desktop:~/meetup$ export PATH=${PATH}:/usr/local/cuda/bin\najeetraina@ajeetraina-desktop:~/meetup$ export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64\najeetraina@ajeetraina-desktop:~/meetup$ source ~/.bashrc\najeetraina@ajeetraina-desktop:~/meetup$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2019 NVIDIA Corporation\nBuilt on Wed_Oct_23_21:14:42_PDT_2019\nCuda compilation tools, release 10.2, V10.2.89\n</code></pre>"},{"location":"nvidia/getting-started/#devicequery","title":"DeviceQuery","text":"<pre><code>$ pwd\n\n/usr/local/cuda/samples/1_Utilities/deviceQuery\nsudo make\n</code></pre> <pre><code>ajeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ sudo make\n/usr/local/cuda-10.2/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_32,code=sm_32 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n/usr/local/cuda-10.2/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_32,code=sm_32 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o\nmkdir -p ../../bin/aarch64/linux/release\ncp deviceQuery ../../bin/aarch64/linux/release\najeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ ls\nMakefile  NsightEclipse.xml  deviceQuery  deviceQuery.cpp  deviceQuery.o  readme.txt\najeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ ./deviceQuery\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3956 MBytes (4148387840 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre>"},{"location":"nvidia/getting-started/#2-verifying-if-it-is-shipped-with-docker-binaries","title":"2. Verifying if it is shipped with Docker Binaries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker version\n[sudo] password for ajeetraina: \nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:       \n</code></pre>"},{"location":"nvidia/getting-started/#3-checking-docker-runtime","title":"3. Checking Docker runtime","text":"<p>Starting with JetPack 4.2, NVIDIA has introduced a container runtime with Docker integration. This custom runtime enables Docker containers to access the underlying GPUs available in the Jetson family.</p> <pre><code>pico@pico1:/tmp/docker-build$ sudo nvidia-docker version\nNVIDIA Docker: 2.0.3\nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:\n</code></pre>"},{"location":"nvidia/getting-started/#installing-docker-compose-on-nvidia-jetson-nano","title":"Installing Docker Compose on NVIDIA Jetson Nano","text":"<p>Jetson Nano doesnt come with Docker Compose installed by default. You will need to install it first:</p> <pre><code>export DOCKER_COMPOSE_VERSION=1.27.4\nsudo apt-get install libhdf5-dev\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose==\"${DOCKER_COMPOSE_VERSION}\"\napt install python3\napt install python3-pip\npip install docker-compose\n</code></pre> <pre><code>docker-compose version\ndocker-compose version 1.26.2, build unknown\ndocker-py version: 4.3.1\nCPython version: 3.6.9\nOpenSSL version: OpenSSL 1.1.1  11 Sep 2018\n</code></pre> <p>Next, add default runtime for NVIDIA:</p> <p>Edit /etc/docker/daemon.json</p> <pre><code>{\n    \"runtimes\": {\n        \"nvidia\": {\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        }\n    },\n\n    \"default-runtime\": \"nvidia\",\n    \"node-generic-resources\": [ \"NVIDIA-GPU=0\" ]\n}\n\n</code></pre> <p>Restart the Docker Daemon</p> <pre><code>systemctl restart docker\n</code></pre>"},{"location":"nvidia/getting-started/#identify-the-jetson-board","title":"Identify the Jetson board","text":"<pre><code>pico@pico1:~$ git clone https://github.com/jetsonhacks/jetsonUtilities\nCloning into 'jetsonUtilities'...\nremote: Enumerating objects: 123, done.\nremote: Counting objects: 100% (39/39), done.\nremote: Compressing objects: 100% (30/30), done.\nremote: Total 123 (delta 15), reused 23 (delta 8), pack-reused 84\nReceiving objects: 100% (123/123), 32.87 KiB | 5.48 MiB/s, done.\nResolving deltas: 100% (49/49), done.\npico@pico1:~$ cd jetson\n-bash: cd: jetson: No such file or directory\npico@pico1:~$ cd jetsonUtilities/\n</code></pre> <pre><code>pico@pico1:~/jetsonUtilities$ ls\nLICENSE  README.md  jetsonInfo.py  scripts\n\npico@pico1:~/jetsonUtilities$ python3 jetsonInfo.py \nNVIDIA Jetson Nano (Developer Kit Version)\n L4T 32.4.4 [ JetPack 4.4.1 ]\n   Ubuntu 18.04.5 LTS\n   Kernel Version: 4.9.140-tegra\n CUDA 10.2.89\n   CUDA Architecture: 5.3\n OpenCV version: 4.1.1\n   OpenCV Cuda: NO\n CUDNN: 8.0.0.180\n TensorRT: 7.1.3.0\n Vision Works: 1.6.0.501\n VPI: 4.4.1-b50\n Vulcan: 1.2.70\n</code></pre>"},{"location":"nvidia/getting-started/#install-the-latest-version-of-cuda","title":"Install the latest version of CUDA","text":"<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/sbsa/cuda-ubuntu1804.pin\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo dpkg -i cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-3-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre>"},{"location":"nvidia/getting-started/#verify-docker-runtime","title":"Verify Docker runtime","text":"<pre><code>docker info | grep runtime\n Runtimes: nvidia runc io.containerd.runc.v2 io.containerd.runtime.v1.linux\n</code></pre>"},{"location":"nvidia/getting-started/#testing-gpu-support","title":"Testing GPU Support","text":"<p>We\u2019ll use the deviceQuery NVIDIA test application (included in L4T) to check that we can access the GPU in the cluster. First, we\u2019ll create a Docker image with the appropriate software, run it directly as Docker, then run it using containerd ctr and finally on the Kubernetes cluster itself.</p>"},{"location":"nvidia/getting-started/#running-devicequery-on-docker-with-gpu-support","title":"Running deviceQuery on Docker with GPU support","text":""},{"location":"nvidia/getting-started/#create-a-directory","title":"Create a directory","text":"<pre><code>mkdir test\ncd test\n</code></pre>"},{"location":"nvidia/getting-started/#copy-the-sample-files","title":"Copy the sample files","text":"<p>Copy the demos where deviceQuery is located to the working directory where the Docker image will be created:</p> <pre><code>cp -R /usr/local/cuda/samples .\n</code></pre>"},{"location":"nvidia/getting-started/#create-a-dockerfile","title":"Create a Dockerfile","text":"<pre><code>FROM nvcr.io/nvidia/l4t-base:r32.5.0\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends make g++\nCOPY ./samples /tmp/samples\nWORKDIR /tmp/samples/1_Utilities/deviceQuery\nRUN make clean &amp;&amp; make\nCMD [\"./deviceQuery\"]\n</code></pre> <pre><code>sudo docker build -t ajeetraina/jetson_devicequery . -f Dockerfile\n</code></pre> <pre><code>pico@pico2:~/test$ sudo docker run --rm --runtime nvidia ajeetraina/jetson_devicequery:latest\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre> <p>Test 2: Running deviceQuery on containerd with GPU support</p> <p>Since K3s uses containerd as its runtime by default, we will use the ctr command line to test and deploy the deviceQuery image we pushed on containerd with this script:</p> <pre><code>#!/bin/bash\nIMAGE=ajeetraina/jetson_devicequery:latest\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml\nctr i pull docker.io/${IMAGE}\nctr run --rm --gpus 0 --tty docker.io/${IMAGE} deviceQuery\n</code></pre>"},{"location":"nvidia/getting-started/#execute-the-script","title":"Execute the script","text":"<pre><code>sudo sh usectr.sh\n</code></pre> <pre><code>sudo sh usectr.sh \ndocker.io/ajeetraina/jetson_devicequery:latest:                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550: done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:4438ebff930fb27930d802553e13457783ca8a597e917c030aea07f8ff6645c0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b1cdeb9e69c95684d703cf96688ed2b333a235d5b33f0843663ff15f62576bd4:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:bf60857fb4964a3e3ce57a900bbe47cd1683587d6c89ecbce4af63f98df600aa:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0aac5305d11a81f47ed76d9663a8d80d2963b61c643acfce0515f0be56f5e301:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:37987db6d6570035e25e713f41e665a6d471d25056bb56b4310ed1cb1d79a100:   done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f0f57d03cad8f8d69b1addf90907b031ccb253b5a9fc5a11db83c51aa311cbfb:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:08c23323368d4fde5347276d543c500e1ff9b712024ca3f85172018e9440d8b0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:04da93b342eb651d6b94c74a934a3290697573a907fa0a06067b538095601745:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f84ceb6e8887e9b3b454813459ee97c2b9730869dbd37d4cca4051958b7a5a36:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:93752947af53e2a3225e145b359b956df36e20521b5dde0fe6d3fb92fd2a9538:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b235194751dee33624fc154603f7e25ecdfbb02538fb7d55fa796df9afa95fee:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:905b1329c1d473c79650e33b882d980b3522fb72e58ecd3456c4fb3c4039fe92:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:8931d5ba88b488c949f77f990e8f9198b153ceb71afd0369eac9c39beb38f2d6:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cfb2938be99fb944fe31165bdf44532a5536865ce53b12eb7758d1e2a51ad33e:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:606a67bb8db9a1111022bdc6406442e11c1a66653136c5c777114bf67b61038a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:2f37138d1c8ac71d9314a0f8996ba69579bbc6ee6a57440557bc7eef486ed292:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9ce7ce1da17c2b8149573d1d73132f61a73083f0cd498eeb7a0da404fd77db14:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a36863a728ec9221c83c745f40511946dfd63beca0f10c9afcc774ef7a98e420:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:86dd6e5994e2c15f2783d8d543327479ccee7f3b20023dd962fdb9a211071e16:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f5299db1221c515de91f59d84b79f2f839f9c94a5d0cc7fad04134e23ec9b88a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:15a5811e1a7bf377cbac066b04e0b36b4c1a41ca63eb3c67c17b734577f6beea:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cb893097de39451407d7167b312ec56eaea80baa041877af8239dbe833fa044b:    done           |++++++++++++++++++++++++++++++++++++++| \nelapsed: 81.4s                                                                    total:  305.5  (3.8 MiB/s)                                       \nunpacking linux/arm64/v8 sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550...\n\ndone\n\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n\n\n</code></pre>"},{"location":"nvidia/getting-started/#test-3-running-devicequery-on-the-k3s-cluster","title":"Test 3: Running deviceQuery on the K3s cluster","text":"<pre><code>pico@pico2:~/test$ cat pod_deviceQuery.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$\n</code></pre> <pre><code>sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery.yaml\npod/devicequery created\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Pending\nIP:           \nIPs:          &lt;none&gt;\nContainers:\n  nvidia:\n    Container ID:  \n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      \n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       ContainerCreating\n    Ready:          False\n    Restart Count:  0\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  78s   default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal  Pulling    77s   kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\npico@pico2:~/test$\n</code></pre> <pre><code>cat pod_deviceQuery_jetson4.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  nodeName: pico4\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$ \n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Running\nIP:           10.42.1.3\nIPs:\n  IP:  10.42.1.3\nContainers:\n  nvidia:\n    Container ID:  containerd://fd502d6bfa55e2f80b2d50bc262e6d6543fd8d09e9708bb78ecec0b2e09621c3\n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      docker.io/ajeetraina/jetson_devicequery@sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550\n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    1\n      Started:      Sun, 13 Jun 2021 09:21:50 -0700\n      Finished:     Sun, 13 Jun 2021 09:21:50 -0700\n    Ready:          False\n    Restart Count:  5\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                    From               Message\n  ----     ------     ----                   ----               -------\n  Normal   Scheduled  7m51s                  default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal   Pulled     5m45s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 2m5.699757621s\n  Normal   Pulled     5m43s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.000839703s\n  Normal   Pulled     5m29s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 967.072951ms\n  Normal   Pulled     4m59s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.025604394s\n  Normal   Created    4m59s (x4 over 5m45s)  kubelet            Created container nvidia\n  Normal   Started    4m59s (x4 over 5m45s)  kubelet            Started container nvidia\n  Warning  BackOff    4m20s (x8 over 5m42s)  kubelet            Back-off restarting failed container\n  Normal   Pulling    2m47s (x6 over 7m51s)  kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery_jetson4.yaml\npod/devicequery configured\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/","title":"Install Docker on Rasperry Pi","text":"<p>Raspberry Pi boards today are not just limited to hobbyists and makers. It is heavily used in the IoT industry as a preferable solution for Linux Edge computing. The Raspberry Pi is a tiny computer about the size of a deck of cards. It uses what\u2019s called a system on a chip, which integrates the CPU and GPU in a single integrated circuit, with the RAM, USB ports, and other components soldered onto the board for an all-in-one package. One can use Raspberry Pi to learn programming skills, build hardware projects, do home automation, implement Kubernetes clusters and Edge computing, and even use them in industrial applications. </p> <p>Docker support for Raspberry Pi was introduced for the first time in 2016 with v1.12 release. At the same time, Rancher community introduced a lightweight Kubernetes distribution(a.k.a. K3s) for Pi box. K3s is a brand new distribution of Kubernetes that is designed for teams that need to deploy applications quickly and reliably to resource-constrained environments. K3s is a Certified Kubernetes distribution designed for production workloads in unattended, resource-constrained, remote locations or inside IoT appliances.</p>"},{"location":"raspberrypi/docker-on-raspberrypi/#why-docker-kubernetes-on-iot-devices","title":"Why Docker &amp; Kubernetes on IoT devices?","text":"<p>Today many organizations are going through a digital transformation process. Digital transformation is the integration of digital technology into almost all areas of a business, fundamentally changing how you operate and deliver value to customers. It\u2019s basically a cultural change.  The common goal for all these organization is to change how they connect with their customers, suppliers and partners. These organizations are taking advantage of innovations offered by technologies such as IoT platforms, big data analytics, or machine learning to modernize their enterprise IT and OT systems. They realize that the complexity of development and deployment of new digital products require new development processes. Consequently, they turn to agile development and infrastructure tools such as Kubernetes.</p> <p>Docker containers &amp; Kubernetes are an excellent choice for deploying complex software to the Edge. The reasons are listed below:</p> <ul> <li>Containers are awesome</li> <li>Consistent across a wide variety of Infrastructure</li> <li>Capable of standalone or clustered operations</li> <li>Easy to upgrade and/or replace containers</li> <li>Support for different infrastructure configs(storage,CPU etc.)</li> <li>Strong Ecosystem(Monitoring, logging, CI, management etc.)</li> </ul> <p>In the first part of this blog post, I will show you how to install the latest version of Docker on the Raspberry Pi board in 5 Minutes.</p>"},{"location":"raspberrypi/docker-on-raspberrypi/#hardware","title":"Hardware:","text":"<ul> <li>Raspberry Pi 4 ( You can order it from Amazon in case you are in India for $35)</li> <li>Micro-SD card reader ( I got it from here )</li> <li>Any Windows or Linux Desktop or Laptop</li> <li>HDMI cable ( I used the HDMI cable of my plasma TV)</li> <li>Internet Connectivity(Wifi/Broadband/Tethering using Mobile) \u2013 to download Docker 1.12.1 package</li> <li>Keyboard &amp; mouse connected to Pi\u2019s USB ports</li> <li>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</li> </ul> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\ufeff\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#using-raspberry-pi-imager","title":"Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <p>SSH to Raspberry Pi nodes</p> <pre><code>$ssh pi@192.168.1.7$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2022 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#step-2-installing-docker-201020-on-each-pi-nodes","title":"Step #2: Installing Docker 20.10.20 on each Pi nodes","text":"<pre><code>sudo curl -sSL https://get.docker.com/ | sh\npi@raspi2:~ $ docker version\nClient: Docker Engine - Community \nVersion:           20.10.20 \nAPI version:       1.41 \nGo version:        go1.12.10 \nGit commit:        baeda1f \nBuilt:             Tue Oct 25 18:01:18 2022 \nOS/Arch:           linux/arm \nExperimental:      false\n\nServer: Docker Engine - Community Engine:  \nVersion:          20.10.20  \nAPI version:      1.41 (minimum version 1.12)  \nGo version:       go1.18.7  \nGit commit:       3056208  \nBuilt:            Tue Oct 25 18:01:18 2022  \nOS/Arch:          linux/arm  \nExperimental:     false \ncontainerd:\n  Version:          1.6.9\n  GitCommit:        1c90a442489720eec95342e1789ee8a5e1b9536f\n runc:\n  Version:          1.1.4\n  GitCommit:        v1.1.4-0-g5fd4c4d\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#running-nginx-docker-container","title":"Running Nginx Docker container","text":"<pre><code>pi@raspi2:~ $ docker run -d -p 80:80 nginx\npi@raspi2:~ $ docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMESd7055f45bf23        nginx               \"/docker-entrypoint.\u2026\"   2 minutes ago       Up About a minute   0.0.0.0:80-&gt;80/tcp   silly_maxwellpi@raspi2:~ $\n</code></pre>"},{"location":"raspberrypi/getting-started/","title":"Getting Started with Rasperry Pi","text":"<p>The Raspberry Pi is a small, low-cost computer developed by the Raspberry Pi Foundation in the United Kingdom. It is intended to promote the teaching of basic computer science in schools and developing countries. The Raspberry Pi is about the size of a credit card and can be used for a variety of tasks including programming, web browsing, and playing videos. It runs on a Linux-based operating system and can be connected to a monitor, keyboard, and mouse to use as a desktop computer, or it can be used with a variety of accessories to control hardware or interact with the internet.</p> <p></p> <p>The Raspberry Pi is a low-cost, credit-card sized computer that plugs into a computer monitor or TV, and uses a standard keyboard and mouse. It is a capable little device that enables people of all ages to explore computing, and to learn how to program in languages like Scratch and Python. It's also used for a variety of DIY projects and as a media center, retro gaming console, and general-purpose computer. Additionally, it can be used for various purposes such as Robotics, home automation, and IoT projects, etc.</p>"},{"location":"raspberrypi/getting-started/#hardware","title":"Hardware:","text":"<ul> <li>Raspberry Pi 4 ( You can order it from Amazon in case you are in India for $35)</li> <li>Micro-SD card reader ( I got it from here )</li> <li>Any Windows or Linux Desktop or Laptop</li> <li>HDMI cable ( I used the HDMI cable of my plasma TV)</li> <li>Internet Connectivity(Wifi/Broadband/Tethering using Mobile) \u2013 to download Docker 1.12.1 package</li> <li>Keyboard &amp; mouse connected to Pi\u2019s USB ports</li> <li>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</li> </ul> <p>Insert the microSD card into your Pi box. Now connect the HDMI cable  from one end of Pi\u2019s HDMI slot to your TV or display unit and mobile charger(recommended 5.1V@1.5A) as shown:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\ufeff\n</code></pre>"},{"location":"raspberrypi/getting-started/#using-raspberry-pi-imager","title":"Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <p>SSH to Raspberry Pi nodes</p> <pre><code>$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2022 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/projects/Pico/","title":"The Pico Project","text":"<p>Object Detection &amp; Text Analytics using Deep Learning Made Simple using Docker, Apache Kafka, IoT &amp; Amazon Rekognition System</p> <p></p>"},{"location":"raspberrypi/projects/Pico/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Intent</li> <li>Hardware</li> <li>Software</li> <li>Activating Raspberry Pi Camera</li> <li>Setting up Docker on Raspberry Pi</li> <li>Preparing Your Raspberry Pi</li> <li>Using Raspberry Pi Imager</li> <li>Installing Docker 19.03 on Raspberry Pi</li> <li>Setting up Apache Kafka running inside Docker container on AWS Cloud EC2 Instance</li> <li>Building up First Node using Docker Machine</li> <li>Building Apache Kafka on 2-Node Docker Swarm Cluster</li> <li>Setting up Pico</li> <li>Running Consumer Scripts on AWS Cloud Instance</li> <li>Running Producer Script on Raspberry Pi</li> <li>References &amp; Resources</li> </ol>"},{"location":"raspberrypi/projects/Pico/#intent","title":"Intent:","text":"<p>The intention with this project is to showcase how easy it is to implement object detection and analytics using Docker containers.Imagine you are able to capture live video streams, identify objects using deep learning, and then trigger actions or notifications based on the identified objects - all using Docker containers. With Pico, you will be able to setup and run a live video capture, analysis, and alerting solution prototype.</p> <p></p> <p>A camera surveils a particular area, streaming video over the network to a video capture client. The client samples video frames and sends them over to AWS, where they are analyzed and stored along with metadata. If certain objects are detected in the analyzed video frames, SMS alerts are sent out. Once a person receives an SMS alert, they will likely want to know what caused it. For that, sampled video frames can be monitored with low latency using a web-based user interface.</p> <p>The Pico framework uses Kafka cluster to acquire data in real-time. Kafka is a message-based distributed publish-subscribe system, which has the advantages of high throughput and perfect fault-tolerant mechanism. The type of data source is the video that generated by the cameras attached to Raspberry Pi. </p> <p></p>"},{"location":"raspberrypi/projects/Pico/#hardware","title":"Hardware","text":"Items Link Reference Raspberry Pi 3 Model B Buy Raspberry Pi Infrared IR Night Vision Surveillance Camera Module 500W Webcam Buy 5MP Raspberry Pi 3 Camera Module W/ HBV FFC Cable Buy"},{"location":"raspberrypi/projects/Pico/#software","title":"Software","text":"<ol> <li>Raspberry Pi OS</li> <li>Docker 19.03.x</li> <li>Python </li> <li>Amazon Cloud Subscription</li> <li>AWS Rekognition Service</li> </ol>"},{"location":"raspberrypi/projects/Pico/#activating-raspberry-pi-camera-module","title":"Activating Raspberry Pi Camera Module","text":"<p>To configure the camera Interface, run the below command as sudo or root user:</p> <pre><code>$ sudo raspi-config\n</code></pre> <p>It will open up command-line UI window, choose Interfacing , select Camera and enable it. Save and exit the CLI window.</p> <p>You will also need to load the required driver \u201cbcm2835-v412\u201d to make your camera module work. If you miss this step, you will end up seeing a blank screen even though the application comes up without any issue.</p> <pre><code># sudo modprobe bcm2835-v4l2\n</code></pre> <p></p>"},{"location":"raspberrypi/projects/Pico/#setting-up-docker-on-raspberry-pi","title":"Setting up Docker on Raspberry Pi","text":""},{"location":"raspberrypi/projects/Pico/#1-preparing-your-raspberry-pi","title":"1. Preparing Your Raspberry Pi","text":"<p>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</p> <p>Visit this link and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#2-using-raspberry-pi-imager","title":"2. Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <pre><code>$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2020 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#3-installing-docker-1903-on-raspberry-pi","title":"3. Installing Docker 19.03 on Raspberry Pi","text":"<pre><code>sudo curl -sSL https://get.docker.com/ | sh\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-docker-binaries","title":"Verifying Docker Binaries","text":"<pre><code>pi@raspi2:~ $ docker version\nClient: Docker Engine - Community \nVersion:           19.03.4 \nAPI version:       1.40 \nGo version:        go1.12.10 \nGit commit:        9013bf5 \nBuilt:             Fri Oct 18 16:03:00 2019 \nOS/Arch:           linux/arm \nExperimental:      false\n\nServer: Docker Engine - Community Engine:  \nVersion:          19.03.8  \nAPI version:      1.40 (minimum version 1.12)  \nGo version:       go1.12.17  \nGit commit:       afacb8b  \nBuilt:            Wed Mar 11 01:29:22 2020  OS/Arch:          linux/arm  Experimental:     false \ncontainerd:  Version:          1.2.10  \nGitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 \nrunc:  Version:          1.0.0-rc8+dev  \nGitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  \nVersion:          0.18.0  \nGitCommit:        fec368\npi@raspi2:~ $\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#setting-up-apache-kafka-running-inside-docker-container-on-aws-cloud-ec2-instance","title":"Setting up Apache Kafka running inside Docker container on AWS Cloud EC2 Instance","text":""},{"location":"raspberrypi/projects/Pico/#pre-requisites","title":"Pre-requisites:","text":"<ul> <li>Docker Desktop for Mac or Windows</li> <li>AWS Account ( You will require t2.medium instances for this)</li> <li>AWS CLI installed</li> <li>Docker Machine installed</li> </ul>"},{"location":"raspberrypi/projects/Pico/#adding-your-credentials","title":"Adding Your Credentials:","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  cat ~/.aws/credentials\n[default]\naws_access_key_id = XXXA \naws_secret_access_key = XX\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-aws-version","title":"Verifying AWS Version","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  aws --version\naws-cli/1.11.107 Python/2.7.10 Darwin/17.7.0 botocore/1.5.70\nSetting up Environmental Variable\n</code></pre> <pre><code>[Captains-Bay]\ud83d\udea9 &gt;  export VPC=vpc-ae59f0d6\n[Captains-Bay]\ud83d\udea9 &gt;  export REGION=us-west-2a\n[Captains-Bay]\ud83d\udea9 &gt;  export SUBNET=subnet-827651c9\n[Captains-Bay]\ud83d\udea9 &gt;  export ZONE=a\n[Captains-Bay]\ud83d\udea9 &gt;  export REGION=us-west-2\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#building-up-first-node-using-docker-machine","title":"Building up First Node using Docker Machine","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  docker-machine create  --driver amazonec2  --amazonec2-access-key=${ACCESS_KEY_ID}  --amazonec2-secret-key=${SECRET_ACCESS_KEY} --amazonec2-region=us-west-2 --amazonec2-vpc-id=vpc-ae59f0d6 --amazonec2-ami=ami-78a22900 --amazonec2-open-port 2377 --amazonec2-open-port 7946 --amazonec2-open-port 4789 --amazonec2-open-port 7946/udp --amazonec2-open-port 4789/udp --amazonec2-open-port 8080 --amazonec2-open-port 443 --amazonec2-open-port 80 --amazonec2-subnet-id=subnet-72dbdb1a --amazonec2-instance-type=t2.micro kafka-swarm-node1\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#listing-out-the-nodes","title":"Listing out the Nodes","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  docker-machine ls\nNAME                ACTIVE   DRIVER      STATE     URL                         SWARM   DOCKER     ERRORS\nkafka-swarm-node1   -        amazonec2   Running   tcp://35.161.106.158:2376           v18.09.6   \nkafka-swarm-node2   -        amazonec2   Running   tcp://54.201.99.75:2376             v18.09.6 \n</code></pre>"},{"location":"raspberrypi/projects/Pico/#initialiating-docker-swarm-manager-node","title":"Initialiating Docker Swarm Manager Node","text":"<pre><code>ubuntu@kafka-swarm-node1:~$ sudo docker swarm init --advertise-addr 172.31.53.71 --listen-addr 172.31.53.71:2377\nSwarm initialized: current node (yui9wqfu7b12hwt4ig4ribpyq) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-xxxxxmr075to2v3k-decb975h5g5da7xxxx 172.31.53.71:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#adding-worker-node","title":"Adding Worker Node","text":"<pre><code>ubuntu@kafka-swarm-node2:~$ sudo docker swarm join --token SWMTKN-1-2xjkynhin0n2zl7xxxk-decb975h5g5daxxxxxxxxn 172.31.53.71:2377\nThis node joined a swarm as a worker.\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-2-node-docker-swarm-mode-cluster","title":"Verifying 2-Node Docker Swarm Mode Cluster","text":"<pre><code>ubuntu@kafka-swarm-node1:~$ sudo docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\nyui9wqfu7b12hwt4ig4ribpyq *   kafka-swarm-node1   Ready               Active              Leader              18.09.6\nvb235xtkejim1hjdnji5luuxh     kafka-swarm-node2   Ready               Active                                  18.09.6\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#installing-docker-compose","title":"Installing Docker Compose","text":"<pre><code>curl -L https://github.com/docker/compose/releases/download/1.25.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   617    0   617    0     0   2212      0 --:--:-- --:--:-- --:--:--  2211\n100 15.5M  100 15.5M    0     0  8693k      0  0:00:01  0:00:01 --:--:-- 20.1M\n</code></pre> <pre><code>root@kafka-swarm-node1:/home/ubuntu/dockerlabs/solution/kafka-swarm# chmod +x /usr/local/bin/docker-compose\n</code></pre> <pre><code>ubuntu@kafka-swarm-node1:~/dockerlabs/solution/kafka-swarm$ sudo docker-compose version\ndocker-compose version 1.25.0-rc1, build 8552e8e2\ndocker-py version: 4.0.1\nCPython version: 3.7.3\nOpenSSL version: OpenSSL 1.1.0j  20 Nov 2018\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#building-apache-kafka-on-2-node-docker-swarm-cluster","title":"Building Apache Kafka on 2-Node Docker Swarm Cluster","text":"<p>Apache Kafka is an open-source stream-processing software platform developed by LinkedIn and donated to the Apache Software Foundation. It is written in Scala and Java. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds.</p> <p>Apache Kafka is a distributed, partitioned, and replicated publish-subscribe messaging system that is used to send high volumes of data, in the form of messages, from one point to another. It replicates these messages across a cluster of servers in order to prevent data loss and allows both online and offline message consumption. This in turn shows the fault-tolerant behaviour of Kafka in the presence of machine failures that also supports low latency message delivery. In a broader sense, Kafka is considered as a unified platform which guarantees zero data loss and handles real-time data feeds.</p>"},{"location":"raspberrypi/projects/Pico/#cloning-the-repository","title":"Cloning the Repository","text":"<pre><code>git clone https://github.com/ajeetraina/developer/solution/iot/ai/pico\ncd pico/kafka/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#using-docker-stack-deploy-to-setup-3-node-kafka-cluster","title":"Using <code>docker stack deploy</code> to setup 3 Node Kafka Cluster","text":"<pre><code>docker stack deploy -c docker-compose.yml mykafka\n</code></pre> <p>By now, you should be able to access kafka manager at https://:9000"},{"location":"raspberrypi/projects/Pico/#adding-a-cluster","title":"Adding a cluster","text":"<ul> <li>Cluster Name = pico (or whatever you want)</li> <li>Cluster Zookeeper Hosts = zk-1:2181,zk-2:2181,zk-3:2181</li> <li>Kafka Version = leave it at 0.9.01 even though we're running 1.0.0</li> <li>Enable JMX Polling = enabled</li> </ul>"},{"location":"raspberrypi/projects/Pico/#adding-a-topic","title":"Adding a Topic","text":"<p>Click on Topic on the top center of the Kafka Manager to create a new topic with the below details -</p> <ul> <li>Topic = testpico</li> <li>Partitions = 6</li> <li>Replication factor = 2</li> </ul> <p>which gives an even spread of the topic across the three kafka nodes.</p> <p>While saving the settings, it might ask to set minimal parameter required. Feel free to follow the instruction provided.</p>"},{"location":"raspberrypi/projects/Pico/#setting-up-pico","title":"Setting up Pico","text":""},{"location":"raspberrypi/projects/Pico/#running-consumer-scripts-on-aws-cloud-instance","title":"Running Consumer Scripts on AWS Cloud Instance","text":"<p>Run the below Docker container for preparing environment for Consumer scripts</p> <pre><code>docker run -d -p 5000:5000 ajeetraina/opencv4-python3 bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#open-up-bash-shell-inside-docker-container","title":"Open up bash shell inside Docker Container","text":"<pre><code>docker exec -it &lt;container-id&gt; bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#remove-the-existing-pico-directory","title":"Remove the existing Pico directory","text":"<pre><code>rm -fr pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#cloning-the-fresh-repository","title":"Cloning the fresh Repository","text":"<pre><code>#git clone https://github.com/ajeetraina/developer/\ncd solutions/iot/ai/pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#locating-the-right-consumer-scripts","title":"Locating the right consumer scripts","text":"<p>You will need 2 scripts - Image Processor and Consumer</p> <pre><code>cd pico/deployment/objects/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#execute-image-processor-script","title":"Execute Image processor Script","text":"<p>This script is placed under hhttps://github.com/ajeetraina/developer/edit/master/solutions/iot/ai/pico/blob/master/deployment/objects/image_processor.py location. Before you run this script, ensure that it has right AWS Access Key and Broker IP address</p> <pre><code>python3 image_processor.py\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#open-up-new-bash-again","title":"Open up new bash again","text":"<pre><code>docker exec -it &lt;container-id&gt; bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#exexute-consumer-script","title":"Exexute Consumer Script","text":"<p>This script is placed under https://github.com/ajeetraina/developer/edit/master/solutions/iot/ai/pico/blob/master/deployment/objects/ directory. Before you run this script, ensure that it has right Broker IP address</p> <pre><code>python3 consumer.py\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#running-producer-script-on-raspberry-pi","title":"Running Producer Script on Raspberry Pi","text":""},{"location":"raspberrypi/projects/Pico/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/ajeetraina/developer\ncd developer/solutions/iot/ai/pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#locating-producer-script","title":"Locating Producer Script","text":"<pre><code>cd pico/deployment/objects/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#edit-producer_camerapy-script-and-add-the-proper-ip-address-for-the-kafka-broker","title":"Edit producer_camera.py script and add the proper IP address for the kafka broker:","text":"<pre><code>brokers = [\"35.221.213.182:9092\"]\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#installing-dependencies","title":"Installing Dependencies","text":"<pre><code>apt install -y python-pip libatlas-base-dev libjasper-dev libqtgui4 python3-pyqt5 python3-pyqt5 libqt4-test\npip3 install kafka-python opencv-python pytz\npip install virtualenv virtualenvwrapper numpy\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#execute-the-script","title":"Execute the script","text":"<pre><code>python3 producer_camera.py\n</code></pre> <p>Please Note: This script should be run post the consumer scripts (Image_Processor &amp; Consumer.py) is executed</p>"},{"location":"raspberrypi/projects/Pico/#testing-object-detection","title":"Testing Object Detection","text":""},{"location":"raspberrypi/projects/Pico/#sequence-of-scripts-execution","title":"Sequence of Scripts Execution","text":""},{"location":"raspberrypi/projects/Pico/#pre-requisite","title":"Pre-requisite:","text":"<ul> <li>Ensure that you have followed all the above steps. </li> <li>Ensure that Docker Swarm is up and running on AWS Cloud</li> </ul>"},{"location":"raspberrypi/projects/Pico/#sequence","title":"Sequence:","text":"<ul> <li>First run the Image_Processor Script on AWS Instance</li> <li>Then run the Consumer.py Script on AWS Instance</li> <li>Finally, run the Producer_camera.py script on Pi</li> </ul> <p>Place an object in front of camera module and watch out for both text as well as object detection under http://broker-ip:5000</p> <p></p>"},{"location":"raspberrypi/projects/Pico/#references-resources","title":"References &amp; Resources","text":"<ul> <li>The Rise of Pico: At the Grace Hopper Celebration India</li> <li>Introducing Pico - Object Detection &amp; Analytics using Docker, IoT &amp; Amazon Rekognition System</li> </ul>"}]}